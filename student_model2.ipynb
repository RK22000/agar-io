{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "new_model = lambda: tf.keras.Sequential(layers=[\n",
    "    tf.keras.layers.Conv2D(32, (5,5), input_shape=(200,320,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D((5,5)),\n",
    "    tf.keras.layers.Conv2D(32, (5,5), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D((5,5)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1000, 'relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(100, 'relu'),\n",
    "    # tf.keras.layers.Dropout(0.1),\n",
    "    # tf.keras.layers.Dense(100, 'relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(6, 'sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6), dtype=float32, numpy=\n",
       "array([[0.5522612 , 0.54378456, 0.5740875 , 0.5704511 , 0.63909924,\n",
       "        0.4262436 ]], dtype=float32)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "model(np.random.random((1,200,320,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "teach_par = 'teacher_preds'\n",
    "csvs = [os.path.join(teach_par, i) for i in os.listdir(teach_par)]\n",
    "dfs = {csv.split(os.sep)[-1][:-4]: pd.read_csv(csv) for csv in csvs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1203, 962, 241)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "files = dfs[\"1\"].columns\n",
    "train_files, val_files = train_test_split(files, test_size=0.2)\n",
    "len(files), len(train_files), len(val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "class StudentTrainSequence(tf.keras.utils.Sequence):\n",
    "    def __init__(self, frame, batch_size) -> None:\n",
    "        self.frame = frame.copy()\n",
    "        self.batch_size = batch_size\n",
    "    def __len__(self):\n",
    "        return ceil(self.frame.shape[1]/self.batch_size)\n",
    "    def __getitem__(self, idx):\n",
    "        low = idx*self.batch_size\n",
    "        high = min(low + self.batch_size, self.frame.shape[1])\n",
    "        batch_files = self.frame.columns[low:high]\n",
    "        batch_y = self.frame.loc[:, batch_files]\n",
    "        batch_y = batch_y > 0.5\n",
    "        batch_y = batch_y.astype(int)\n",
    "        batch_y  = batch_y.to_numpy().T\n",
    "        batch_x = batch_files\n",
    "        # batch_x = [tf.io.read_file(f) for f in batch_x]\n",
    "        # batch_x = [tf.image.resize(tf.io.decode_png(f), (200,320)) for f in batch_x]\n",
    "        # batch_x = [tf.image.convert_image_dtype(img, tf.float32) for img in batch_x]\n",
    "        # batch_x = tf.stack(batch_x)\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([734, 751, 755, 746, 718, 778])"
      ]
     },
     "execution_count": 766,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = StudentTrainSequence(dfs[\"raw\"], 1200)\n",
    "np.sum(seq[0][1],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 749,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i+=1\n",
    "seq[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfs = {i: dfs[i].loc[:, train_files] for i in dfs.keys()}\n",
    "val_dfs = {i: dfs[i].loc[:, val_files] for i in dfs.keys()}\n",
    "train_seq = {i: StudentTrainSequence(train_dfs[i], 100) for i in train_dfs.keys()}\n",
    "val_seq = {i: StudentTrainSequence(val_dfs[i], 100) for i in val_dfs.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1181,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = new_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_30 (Conv2D)          (None, 196, 316, 32)      2432      \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPooli  (None, 39, 63, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 35, 59, 32)        25632     \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPooli  (None, 7, 11, 32)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 2464)              0         \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 1000)              2465000   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 100)               100100    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 6)                 606       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2593770 (9.89 MB)\n",
      "Trainable params: 2593770 (9.89 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1183,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\"adam\",\n",
    "              tf.keras.losses.BinaryFocalCrossentropy(),\n",
    "              jit_compile=True)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10/10 [==============================] - 44s 4s/step - loss: 14.4880 - val_loss: 0.1676\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 46s 4s/step - loss: 0.1660 - val_loss: 0.1579\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 46s 5s/step - loss: 0.1585 - val_loss: 0.1529\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 47s 5s/step - loss: 0.1483 - val_loss: 0.1557\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 52s 5s/step - loss: 0.1379 - val_loss: 0.1578\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(\n",
    "    train_seq['raw'],\n",
    "    validation_data=val_seq['raw'],\n",
    "    epochs=5,\n",
    "    callbacks=[callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33a404e631124127b2fc917d0d0f02af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None + [62. 16. 14.  4.  2.  2.]\n",
      "[62. 16. 14.  4.  2.  2.] + [80. 11.  5.  2.  2.  0.]\n",
      "[142.  27.  19.   6.   4.   2.] + [71. 10.  8.  2.  6.  3.]\n",
      "[213.  37.  27.   8.  10.   5.] + [80. 14.  2.  1.  1.  2.]\n",
      "[293.  51.  29.   9.  11.   7.] + [79.  8.  4.  3.  4.  2.]\n",
      "[372.  59.  33.  12.  15.   9.] + [78. 11.  3.  2.  2.  4.]\n",
      "[450.  70.  36.  14.  17.  13.] + [76.  7.  9.  5.  1.  2.]\n",
      "[526.  77.  45.  19.  18.  15.] + [75. 13.  6.  4.  1.  1.]\n",
      "[601.  90.  51.  23.  19.  16.] + [75. 13.  7.  3.  1.  1.]\n",
      "[676. 103.  58.  26.  20.  17.] + [73. 14.  6.  1.  3.  3.]\n",
      "[749. 117.  64.  27.  23.  20.] + [74.  9.  8.  3.  4.  2.]\n",
      "[823. 126.  72.  30.  27.  22.] + [73.  9.  7.  5.  3.  3.]\n",
      "[896. 135.  79.  35.  30.  25.] + [3. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "y_sum = None\n",
    "for x,y in tqdm(StudentTrainSequence(dfs[\"raw\"], 100)):\n",
    "    y_ = y\n",
    "    # ysum = np.sum(y_, 0)\n",
    "    ysum = np.argmax(y_, 1)\n",
    "    ysum = tf.one_hot(ysum, 6)\n",
    "    ysum = np.sum(ysum, 0)\n",
    "    print(f\"{y_sum} + {ysum}\")\n",
    "    y_sum = ysum if y_sum is None else y_sum + ysum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([899., 135.,  79.,  35.,  30.,  25.], dtype=float32)"
      ]
     },
     "execution_count": 1190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Hard Raw Label sum': array([1203.,    0.,    0., 1203.,    0., 1203.], dtype=float32),\n",
       " 'Hard Raw Label sum for binary_cross_entropy': array([801.1371 , 921.9782 , 879.74976, 887.7303 , 880.52277, 890.559  ],\n",
       "       dtype=float32),\n",
       " 'Random_model': array([761.31714, 718.2629 , 743.02924, 758.7735 , 753.42206, 765.1477 ],\n",
       "       dtype=float32),\n",
       " 'Teacher_labels': array([737, 753, 758, 749, 721, 781]),\n",
       " 'Double All Model': array([637.0535 , 667.4937 , 649.6967 , 645.3023 , 629.6685 , 648.58563],\n",
       "       dtype=float32),\n",
       " 'Dropout Model': array([771.61914, 754.52856, 755.0897 , 747.3504 , 743.7831 , 757.8667 ],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 1079,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record['Dropout Model'] = y_sum\n",
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6), dtype=float32, numpy=\n",
       "array([[0.4941304 , 0.5010556 , 0.49523175, 0.49499378, 0.49196184,\n",
       "        0.49035382]], dtype=float32)>"
      ]
     },
     "execution_count": 1178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(np.random.random((1,200,320,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1179,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('student5.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Tensorflow: Done    \n",
      "loading weights\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'models.model_student' from 'd:\\\\Projects\\\\Agar.io\\\\models\\\\model_student.py'>"
      ]
     },
     "execution_count": 995,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import models.model_student as student\n",
    "import importlib\n",
    "importlib.reload(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.5083178  0.50923455 0.50519145 0.49928555 0.4986197  0.51128477]], shape=(1, 6), dtype=float32)\n",
      "tf.Tensor([[0.5083178  0.50923455 0.50519145 0.49928555 0.4986197  0.51128477]], shape=(1, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "r = np.random.random((1,200,320,3))\n",
    "print(model(r))\n",
    "print(student.model(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
