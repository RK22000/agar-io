{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Teaching labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models.model_student as student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "all_files = tf.data.Dataset.list_files(\"runs2\\\\*\\\\.fullpic\\\\*.png\")\n",
    "files = list(all_files.take(1203).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import models.model_experiemnt_lab as teacher\n",
    "import numpy as np\n",
    "def file_to_pred(f, T=1):\n",
    "    im = Image.open(f)\n",
    "    im = im.resize((320,200))\n",
    "    preds = teacher.make_preds(im)\n",
    "    # preds = np.exp(preds/T)/sum(np.exp(preds/T))\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "999b63388734424bb4a14aef3100b48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1203 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import threading\n",
    "T=1\n",
    "def get_raw_preds():\n",
    "    global raw_preds\n",
    "    raw_preds = [file_to_pred(i,T) for i in tqdm(files)]\n",
    "thread = threading.Thread(target=get_raw_preds)\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1203"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_preds = {i:[np.exp(p[:,0]/i)/sum(np.exp(p[:,0]/i)) for p in raw_preds] for i in [0.05, 0.1, 0.5, 1, 1.5]}\n",
    "sum_preds = [p[:,0]/sum(p[:,0]) for p in raw_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dfs = {i:pd.DataFrame({f: p for f,p in zip(files, soft_preds[i])}) for i in soft_preds.keys()}\n",
    "dfs['sum_normal'] = pd.DataFrame({f: p for f,p in zip(files, sum_preds)})\n",
    "dfs['raw'] = pd.DataFrame({f: p[:,0] for f,p in zip(files, raw_preds)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>runs2\\\\00102\\\\.fullpic\\\\0000000004+system.png</th>\n",
       "      <th>runs2\\\\00317\\\\.fullpic\\\\0000000002+system.png</th>\n",
       "      <th>runs2\\\\00017\\\\.fullpic\\\\0000000032+system.png</th>\n",
       "      <th>runs2\\\\00163\\\\.fullpic\\\\0000000078+system.png</th>\n",
       "      <th>runs2\\\\00235\\\\.fullpic\\\\0000000054+system.png</th>\n",
       "      <th>runs2\\\\00474\\\\.fullpic\\\\0000000038+system.png</th>\n",
       "      <th>runs2\\\\00115\\\\.fullpic\\\\0000000063+system.png</th>\n",
       "      <th>runs2\\\\00341\\\\.fullpic\\\\0000000010+system.png</th>\n",
       "      <th>runs2\\\\00145\\\\.fullpic\\\\0000000025+system.png</th>\n",
       "      <th>runs2\\\\00054\\\\.fullpic\\\\0000000013+system.png</th>\n",
       "      <th>...</th>\n",
       "      <th>runs2\\\\00369\\\\.fullpic\\\\0000000011+system.png</th>\n",
       "      <th>runs2\\\\00396\\\\.fullpic\\\\0000000001+system.png</th>\n",
       "      <th>runs2\\\\00147\\\\.fullpic\\\\0000000062+system.png</th>\n",
       "      <th>runs2\\\\00412\\\\.fullpic\\\\0000000008+system.png</th>\n",
       "      <th>runs2\\\\00536\\\\.fullpic\\\\0000000043+system.png</th>\n",
       "      <th>runs2\\\\00001\\\\.fullpic\\\\0000000011+system.png</th>\n",
       "      <th>runs2\\\\00163\\\\.fullpic\\\\0000000074+system.png</th>\n",
       "      <th>runs2\\\\00010\\\\.fullpic\\\\0000000016+system.png</th>\n",
       "      <th>runs2\\\\00525\\\\.fullpic\\\\0000000046+system.png</th>\n",
       "      <th>runs2\\\\00394\\\\.fullpic\\\\0000000008+system.png</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.087301</td>\n",
       "      <td>0.222189</td>\n",
       "      <td>0.599788</td>\n",
       "      <td>0.985794</td>\n",
       "      <td>0.999261</td>\n",
       "      <td>0.906918</td>\n",
       "      <td>0.980780</td>\n",
       "      <td>0.283804</td>\n",
       "      <td>0.822787</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.911989</td>\n",
       "      <td>0.634173</td>\n",
       "      <td>0.905701</td>\n",
       "      <td>0.660436</td>\n",
       "      <td>0.662994</td>\n",
       "      <td>0.713454</td>\n",
       "      <td>0.892405</td>\n",
       "      <td>0.999891</td>\n",
       "      <td>0.789046</td>\n",
       "      <td>0.975602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.124052</td>\n",
       "      <td>0.042333</td>\n",
       "      <td>0.553326</td>\n",
       "      <td>0.996808</td>\n",
       "      <td>0.764664</td>\n",
       "      <td>0.970123</td>\n",
       "      <td>0.870806</td>\n",
       "      <td>0.935816</td>\n",
       "      <td>0.957210</td>\n",
       "      <td>0.999932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.904266</td>\n",
       "      <td>0.992675</td>\n",
       "      <td>0.993889</td>\n",
       "      <td>0.470999</td>\n",
       "      <td>0.728106</td>\n",
       "      <td>0.472588</td>\n",
       "      <td>0.960322</td>\n",
       "      <td>0.043001</td>\n",
       "      <td>0.745661</td>\n",
       "      <td>0.998113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.066871</td>\n",
       "      <td>0.028930</td>\n",
       "      <td>0.870369</td>\n",
       "      <td>0.949255</td>\n",
       "      <td>0.752066</td>\n",
       "      <td>0.972466</td>\n",
       "      <td>0.856692</td>\n",
       "      <td>0.982205</td>\n",
       "      <td>0.974445</td>\n",
       "      <td>0.767058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246189</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999898</td>\n",
       "      <td>0.144189</td>\n",
       "      <td>0.834711</td>\n",
       "      <td>0.165992</td>\n",
       "      <td>0.919098</td>\n",
       "      <td>0.775293</td>\n",
       "      <td>0.903880</td>\n",
       "      <td>0.999974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.073110</td>\n",
       "      <td>0.081679</td>\n",
       "      <td>0.461081</td>\n",
       "      <td>0.594493</td>\n",
       "      <td>0.688664</td>\n",
       "      <td>0.922850</td>\n",
       "      <td>0.775210</td>\n",
       "      <td>0.922588</td>\n",
       "      <td>0.890517</td>\n",
       "      <td>0.639912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.747838</td>\n",
       "      <td>0.989484</td>\n",
       "      <td>0.472735</td>\n",
       "      <td>0.042126</td>\n",
       "      <td>0.305730</td>\n",
       "      <td>0.344170</td>\n",
       "      <td>0.825091</td>\n",
       "      <td>0.982653</td>\n",
       "      <td>0.986104</td>\n",
       "      <td>0.992600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.069681</td>\n",
       "      <td>0.060287</td>\n",
       "      <td>0.540846</td>\n",
       "      <td>0.834478</td>\n",
       "      <td>0.617845</td>\n",
       "      <td>0.923751</td>\n",
       "      <td>0.470351</td>\n",
       "      <td>0.976705</td>\n",
       "      <td>0.908055</td>\n",
       "      <td>0.302170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.673010</td>\n",
       "      <td>0.972093</td>\n",
       "      <td>0.979582</td>\n",
       "      <td>0.316141</td>\n",
       "      <td>0.597016</td>\n",
       "      <td>0.448714</td>\n",
       "      <td>0.943219</td>\n",
       "      <td>0.911375</td>\n",
       "      <td>0.971588</td>\n",
       "      <td>0.990894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.149883</td>\n",
       "      <td>0.060169</td>\n",
       "      <td>0.783717</td>\n",
       "      <td>0.597894</td>\n",
       "      <td>0.974850</td>\n",
       "      <td>0.936873</td>\n",
       "      <td>0.967320</td>\n",
       "      <td>0.973124</td>\n",
       "      <td>0.993774</td>\n",
       "      <td>0.988679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.604072</td>\n",
       "      <td>0.192377</td>\n",
       "      <td>0.998003</td>\n",
       "      <td>0.139393</td>\n",
       "      <td>0.875005</td>\n",
       "      <td>0.403869</td>\n",
       "      <td>0.869902</td>\n",
       "      <td>0.961350</td>\n",
       "      <td>0.902294</td>\n",
       "      <td>0.962599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 1203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   runs2\\\\00102\\\\.fullpic\\\\0000000004+system.png  \\\n",
       "0                                       0.087301   \n",
       "1                                       0.124052   \n",
       "2                                       0.066871   \n",
       "3                                       0.073110   \n",
       "4                                       0.069681   \n",
       "5                                       0.149883   \n",
       "\n",
       "   runs2\\\\00317\\\\.fullpic\\\\0000000002+system.png  \\\n",
       "0                                       0.222189   \n",
       "1                                       0.042333   \n",
       "2                                       0.028930   \n",
       "3                                       0.081679   \n",
       "4                                       0.060287   \n",
       "5                                       0.060169   \n",
       "\n",
       "   runs2\\\\00017\\\\.fullpic\\\\0000000032+system.png  \\\n",
       "0                                       0.599788   \n",
       "1                                       0.553326   \n",
       "2                                       0.870369   \n",
       "3                                       0.461081   \n",
       "4                                       0.540846   \n",
       "5                                       0.783717   \n",
       "\n",
       "   runs2\\\\00163\\\\.fullpic\\\\0000000078+system.png  \\\n",
       "0                                       0.985794   \n",
       "1                                       0.996808   \n",
       "2                                       0.949255   \n",
       "3                                       0.594493   \n",
       "4                                       0.834478   \n",
       "5                                       0.597894   \n",
       "\n",
       "   runs2\\\\00235\\\\.fullpic\\\\0000000054+system.png  \\\n",
       "0                                       0.999261   \n",
       "1                                       0.764664   \n",
       "2                                       0.752066   \n",
       "3                                       0.688664   \n",
       "4                                       0.617845   \n",
       "5                                       0.974850   \n",
       "\n",
       "   runs2\\\\00474\\\\.fullpic\\\\0000000038+system.png  \\\n",
       "0                                       0.906918   \n",
       "1                                       0.970123   \n",
       "2                                       0.972466   \n",
       "3                                       0.922850   \n",
       "4                                       0.923751   \n",
       "5                                       0.936873   \n",
       "\n",
       "   runs2\\\\00115\\\\.fullpic\\\\0000000063+system.png  \\\n",
       "0                                       0.980780   \n",
       "1                                       0.870806   \n",
       "2                                       0.856692   \n",
       "3                                       0.775210   \n",
       "4                                       0.470351   \n",
       "5                                       0.967320   \n",
       "\n",
       "   runs2\\\\00341\\\\.fullpic\\\\0000000010+system.png  \\\n",
       "0                                       0.283804   \n",
       "1                                       0.935816   \n",
       "2                                       0.982205   \n",
       "3                                       0.922588   \n",
       "4                                       0.976705   \n",
       "5                                       0.973124   \n",
       "\n",
       "   runs2\\\\00145\\\\.fullpic\\\\0000000025+system.png  \\\n",
       "0                                       0.822787   \n",
       "1                                       0.957210   \n",
       "2                                       0.974445   \n",
       "3                                       0.890517   \n",
       "4                                       0.908055   \n",
       "5                                       0.993774   \n",
       "\n",
       "   runs2\\\\00054\\\\.fullpic\\\\0000000013+system.png  ...  \\\n",
       "0                                       0.999997  ...   \n",
       "1                                       0.999932  ...   \n",
       "2                                       0.767058  ...   \n",
       "3                                       0.639912  ...   \n",
       "4                                       0.302170  ...   \n",
       "5                                       0.988679  ...   \n",
       "\n",
       "   runs2\\\\00369\\\\.fullpic\\\\0000000011+system.png  \\\n",
       "0                                       0.911989   \n",
       "1                                       0.904266   \n",
       "2                                       0.246189   \n",
       "3                                       0.747838   \n",
       "4                                       0.673010   \n",
       "5                                       0.604072   \n",
       "\n",
       "   runs2\\\\00396\\\\.fullpic\\\\0000000001+system.png  \\\n",
       "0                                       0.634173   \n",
       "1                                       0.992675   \n",
       "2                                       0.999999   \n",
       "3                                       0.989484   \n",
       "4                                       0.972093   \n",
       "5                                       0.192377   \n",
       "\n",
       "   runs2\\\\00147\\\\.fullpic\\\\0000000062+system.png  \\\n",
       "0                                       0.905701   \n",
       "1                                       0.993889   \n",
       "2                                       0.999898   \n",
       "3                                       0.472735   \n",
       "4                                       0.979582   \n",
       "5                                       0.998003   \n",
       "\n",
       "   runs2\\\\00412\\\\.fullpic\\\\0000000008+system.png  \\\n",
       "0                                       0.660436   \n",
       "1                                       0.470999   \n",
       "2                                       0.144189   \n",
       "3                                       0.042126   \n",
       "4                                       0.316141   \n",
       "5                                       0.139393   \n",
       "\n",
       "   runs2\\\\00536\\\\.fullpic\\\\0000000043+system.png  \\\n",
       "0                                       0.662994   \n",
       "1                                       0.728106   \n",
       "2                                       0.834711   \n",
       "3                                       0.305730   \n",
       "4                                       0.597016   \n",
       "5                                       0.875005   \n",
       "\n",
       "   runs2\\\\00001\\\\.fullpic\\\\0000000011+system.png  \\\n",
       "0                                       0.713454   \n",
       "1                                       0.472588   \n",
       "2                                       0.165992   \n",
       "3                                       0.344170   \n",
       "4                                       0.448714   \n",
       "5                                       0.403869   \n",
       "\n",
       "   runs2\\\\00163\\\\.fullpic\\\\0000000074+system.png  \\\n",
       "0                                       0.892405   \n",
       "1                                       0.960322   \n",
       "2                                       0.919098   \n",
       "3                                       0.825091   \n",
       "4                                       0.943219   \n",
       "5                                       0.869902   \n",
       "\n",
       "   runs2\\\\00010\\\\.fullpic\\\\0000000016+system.png  \\\n",
       "0                                       0.999891   \n",
       "1                                       0.043001   \n",
       "2                                       0.775293   \n",
       "3                                       0.982653   \n",
       "4                                       0.911375   \n",
       "5                                       0.961350   \n",
       "\n",
       "   runs2\\\\00525\\\\.fullpic\\\\0000000046+system.png  \\\n",
       "0                                       0.789046   \n",
       "1                                       0.745661   \n",
       "2                                       0.903880   \n",
       "3                                       0.986104   \n",
       "4                                       0.971588   \n",
       "5                                       0.902294   \n",
       "\n",
       "   runs2\\\\00394\\\\.fullpic\\\\0000000008+system.png  \n",
       "0                                       0.975602  \n",
       "1                                       0.998113  \n",
       "2                                       0.999974  \n",
       "3                                       0.992600  \n",
       "4                                       0.990894  \n",
       "5                                       0.962599  \n",
       "\n",
       "[6 rows x 1203 columns]"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['raw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[0.05][files[0]], dfs['sum_normal'][files[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "par_dir = 'teacher_preds'\n",
    "os.makedirs(par_dir, exist_ok=True)\n",
    "for i in dfs.keys():\n",
    "    dfs[i].to_csv(os.path.join(par_dir, f\"{i}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Teaching Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "teach_par = 'teacher_preds'\n",
    "csvs = [os.path.join(teach_par, i) for i in os.listdir(teach_par)]\n",
    "dfs = {csv.split(os.sep)[-1][:-4]: pd.read_csv(csv) for csv in csvs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1203, 962, 241)"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "files = dfs[\"1\"].columns\n",
    "train_files, val_files = train_test_split(files, test_size=0.2)\n",
    "len(files), len(train_files), len(val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from math import ceil\n",
    "# def batched(gen, batch_size):\n",
    "#     gen = iter(gen)\n",
    "#     def g():\n",
    "#         nxt = []\n",
    "#         try:\n",
    "#             for _ in range(batch_size):\n",
    "#                 nxt.append(next(gen))\n",
    "#         except StopIteration as e:\n",
    "#             if len(nxt)==0:\n",
    "#                 raise e\n",
    "#         nxt = list(zip(*nxt))\n",
    "#         nxt = [np.array(i) for i in nxt]\n",
    "#         yield nxt\n",
    "#     return g\n",
    "class StudentTrainSequence(tf.keras.utils.Sequence):\n",
    "    def __init__(self, frame, batch_size) -> None:\n",
    "        self.frame = frame\n",
    "        self.batch_size = batch_size\n",
    "    def __len__(self):\n",
    "        return ceil(self.frame.shape[1]/self.batch_size)\n",
    "    def __getitem__(self, idx):\n",
    "        low = idx*self.batch_size\n",
    "        high = min(low + self.batch_size, self.frame.shape[1])\n",
    "        batch_files = self.frame.columns[low:high]\n",
    "        batch_y = self.frame.loc[:, batch_files].to_numpy().T\n",
    "        batch_x = batch_files\n",
    "        batch_x = [tf.io.read_file(f) for f in batch_x]\n",
    "        batch_x = [tf.image.resize(tf.io.decode_png(f), (200,320)) for f in batch_x]\n",
    "        batch_x = [tf.image.convert_image_dtype(img, tf.float32) for img in batch_x]\n",
    "        batch_x = tf.stack(batch_x)\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\Projects\\Agar.io\\student_model.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Projects/Agar.io/student_model.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m seq \u001b[39m=\u001b[39m StudentTrainSequence(dfs[\u001b[39m\"\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m\"\u001b[39;49m], \u001b[39m3\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/Agar.io/student_model.ipynb#X44sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m i,j \u001b[39m=\u001b[39m seq[\u001b[39m0\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/Agar.io/student_model.ipynb#X44sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m i\u001b[39m.\u001b[39mshape, j\u001b[39m.\u001b[39mshape\n",
      "\u001b[1;31mKeyError\u001b[0m: '1'"
     ]
    }
   ],
   "source": [
    "seq = StudentTrainSequence(dfs[\"1\"], 3)\n",
    "i,j = seq[0]\n",
    "i.shape, j.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfs = {i: dfs[i].loc[:, train_files] for i in dfs.keys()}\n",
    "val_dfs = {i: dfs[i].loc[:, val_files] for i in dfs.keys()}\n",
    "train_seq = {i: StudentTrainSequence(train_dfs[i], 100) for i in train_dfs.keys()}\n",
    "val_seq = {i: StudentTrainSequence(val_dfs[i], 100) for i in val_dfs.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Tensorflow: Done    \n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 196, 316, 32)      2432      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 39, 63, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 35, 59, 32)        25632     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 7, 11, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2464)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              2465000   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1000)              1001000   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               100100    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 6)                 606       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3594770 (13.71 MB)\n",
      "Trainable params: 3594770 (13.71 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import models.model_student as student\n",
    "student.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_par = \"student_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(student_par, exist_ok=True)\n",
    "student.model.save_weights(os.path.join(student_par, 'blank.keras'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student.model.load_weights(os.path.join(student_par, 'blank.keras'))\n",
    "student.model.compile(\"adam\",\n",
    "              tf.keras.losses.CategoricalCrossentropy(),\n",
    "              jit_compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Temp_0.05\n",
      "10/10 [==============================] - 65s 6s/step - loss: 69.2934 - val_loss: 1.8037\n",
      "Model: Temp_0.1\n",
      "10/10 [==============================] - 61s 6s/step - loss: 65.4549 - val_loss: 1.7936\n",
      "Model: Temp_0.5\n",
      "10/10 [==============================] - 61s 6s/step - loss: 72.3306 - val_loss: 1.7949\n",
      "Model: Temp_1.5\n",
      "10/10 [==============================] - 59s 6s/step - loss: 66.7552 - val_loss: 1.8036\n",
      "Model: Temp_1\n",
      "10/10 [==============================] - 60s 6s/step - loss: 57.3983 - val_loss: 1.8002\n",
      "Model: Temp_sum_normal\n",
      "10/10 [==============================] - 56s 5s/step - loss: 65.9213 - val_loss: 1.8020\n",
      "Model: Temp_0.05\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 57s 5s/step - loss: 1.7999 - val_loss: 1.7906\n",
      "Model: Temp_0.1\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 56s 5s/step - loss: 1.7955 - val_loss: 1.7910\n",
      "Model: Temp_0.5\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 58s 5s/step - loss: 1.7949 - val_loss: 1.7919\n",
      "Model: Temp_1.5\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 58s 5s/step - loss: 1.7943 - val_loss: 1.7918\n",
      "Model: Temp_1\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 57s 5s/step - loss: 1.7938 - val_loss: 1.7918\n",
      "Model: Temp_sum_normal\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 58s 5s/step - loss: 1.7953 - val_loss: 1.7913\n",
      "Model: Temp_0.05\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 58s 5s/step - loss: 1.7913 - val_loss: 1.7908\n",
      "Model: Temp_0.1\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 59s 6s/step - loss: 1.7905 - val_loss: 1.7911\n",
      "Model: Temp_0.5\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 62s 6s/step - loss: 1.7916 - val_loss: 1.7917\n",
      "Model: Temp_1.5\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 59s 6s/step - loss: 1.7918 - val_loss: 1.7918\n",
      "Model: Temp_1\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 56s 5s/step - loss: 1.7918 - val_loss: 1.7918\n",
      "Model: Temp_sum_normal\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 56s 5s/step - loss: 1.7912 - val_loss: 1.7913\n",
      "Model: Temp_0.05\n",
      "Epoch 4/4\n",
      "10/10 [==============================] - 57s 5s/step - loss: 1.7887 - val_loss: 1.7900\n",
      "Model: Temp_0.1\n",
      "Epoch 4/4\n",
      "10/10 [==============================] - 56s 5s/step - loss: 1.7900 - val_loss: 1.7916\n",
      "Model: Temp_0.5\n",
      "Epoch 4/4\n",
      "10/10 [==============================] - 60s 5s/step - loss: 1.7915 - val_loss: 1.7919\n",
      "Model: Temp_1.5\n",
      "Epoch 4/4\n",
      "10/10 [==============================] - 54s 5s/step - loss: 1.7917 - val_loss: 1.7918\n",
      "Model: Temp_1\n",
      "Epoch 4/4\n",
      "10/10 [==============================] - 61s 6s/step - loss: 1.7917 - val_loss: 1.7918\n",
      "Model: Temp_sum_normal\n",
      "Epoch 4/4\n",
      "10/10 [==============================] - 54s 5s/step - loss: 1.7924 - val_loss: 1.7912\n",
      "Model: Temp_0.05\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 54s 5s/step - loss: 1.7886 - val_loss: 1.7900\n",
      "Model: Temp_0.1\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 55s 5s/step - loss: 1.7904 - val_loss: 1.7911\n",
      "Model: Temp_0.5\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 53s 5s/step - loss: 1.7915 - val_loss: 1.7919\n",
      "Model: Temp_1.5\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 49s 5s/step - loss: 1.7918 - val_loss: 1.7918\n",
      "Model: Temp_1\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 50s 5s/step - loss: 1.7917 - val_loss: 1.7918\n",
      "Model: Temp_sum_normal\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 50s 5s/step - loss: 1.7912 - val_loss: 1.7913\n",
      "Model: Temp_0.05\n",
      "Epoch 6/6\n",
      "10/10 [==============================] - 49s 5s/step - loss: 1.7889 - val_loss: 1.7904\n",
      "Model: Temp_0.1\n",
      "Epoch 6/6\n",
      "10/10 [==============================] - 50s 5s/step - loss: 1.7885 - val_loss: 1.7908\n",
      "Model: Temp_0.5\n",
      "Epoch 6/6\n",
      "10/10 [==============================] - 49s 5s/step - loss: 1.7916 - val_loss: 1.7919\n",
      "Model: Temp_1.5\n",
      "Epoch 6/6\n",
      "10/10 [==============================] - 48s 5s/step - loss: 1.7918 - val_loss: 1.7918\n",
      "Model: Temp_1\n",
      "Epoch 6/6\n",
      "10/10 [==============================] - 49s 5s/step - loss: 1.7917 - val_loss: 1.7918\n",
      "Model: Temp_sum_normal\n",
      "Epoch 6/6\n",
      "10/10 [==============================] - 48s 5s/step - loss: 1.7911 - val_loss: 1.7913\n",
      "Model: Temp_0.05\n",
      "Epoch 7/7\n",
      "10/10 [==============================] - 49s 5s/step - loss: 1.7892 - val_loss: 1.7912\n",
      "Model: Temp_0.1\n",
      "Epoch 7/7\n",
      "10/10 [==============================] - 48s 5s/step - loss: 1.7906 - val_loss: 1.7914\n",
      "Model: Temp_0.5\n",
      "Epoch 7/7\n",
      "10/10 [==============================] - 54s 5s/step - loss: 1.7915 - val_loss: 1.7918\n",
      "Model: Temp_1.5\n",
      "Epoch 7/7\n",
      "10/10 [==============================] - 50s 5s/step - loss: 1.7917 - val_loss: 1.7918\n",
      "Model: Temp_1\n",
      "Epoch 7/7\n",
      "10/10 [==============================] - 48s 5s/step - loss: 1.7917 - val_loss: 1.7918\n",
      "Model: Temp_sum_normal\n",
      "Epoch 7/7\n",
      "10/10 [==============================] - 50s 5s/step - loss: 1.7913 - val_loss: 1.7913\n",
      "Model: Temp_0.05\n",
      "Epoch 8/8\n",
      "10/10 [==============================] - 49s 5s/step - loss: 1.7879 - val_loss: 1.7913\n",
      "Model: Temp_0.1\n",
      "Epoch 8/8\n",
      "10/10 [==============================] - 49s 5s/step - loss: 1.7898 - val_loss: 1.7913\n",
      "Model: Temp_0.5\n",
      "Epoch 8/8\n",
      "10/10 [==============================] - 53s 5s/step - loss: 1.7915 - val_loss: 1.7918\n",
      "Model: Temp_1.5\n",
      "Epoch 8/8\n",
      "10/10 [==============================] - 57s 5s/step - loss: 1.7917 - val_loss: 1.7918\n",
      "Model: Temp_1\n",
      "Epoch 8/8\n",
      "10/10 [==============================] - 49s 5s/step - loss: 1.7917 - val_loss: 1.7918\n",
      "Model: Temp_sum_normal\n",
      "Epoch 8/8\n",
      "10/10 [==============================] - 49s 5s/step - loss: 1.7911 - val_loss: 1.7912\n",
      "Model: Temp_0.05\n",
      "Epoch 9/9\n",
      "10/10 [==============================] - 61s 6s/step - loss: 1.7865 - val_loss: 1.7899\n",
      "Model: Temp_0.1\n",
      "Epoch 9/9\n",
      "10/10 [==============================] - 51s 5s/step - loss: 1.7895 - val_loss: 1.7910\n",
      "Model: Temp_0.5\n",
      "Epoch 9/9\n",
      "10/10 [==============================] - 49s 5s/step - loss: 1.7915 - val_loss: 1.7918\n",
      "Model: Temp_1.5\n",
      "Epoch 9/9\n",
      "10/10 [==============================] - 49s 5s/step - loss: 1.7917 - val_loss: 1.7918\n",
      "Model: Temp_1\n",
      "Epoch 9/9\n",
      "10/10 [==============================] - 49s 5s/step - loss: 1.7917 - val_loss: 1.7918\n",
      "Model: Temp_sum_normal\n",
      "Epoch 9/9\n",
      "10/10 [==============================] - 49s 5s/step - loss: 1.7910 - val_loss: 1.7913\n",
      "Model: Temp_0.05\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 49s 5s/step - loss: 1.7864 - val_loss: 1.7937\n",
      "Model: Temp_0.1\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 49s 5s/step - loss: 1.7904 - val_loss: 1.7910\n",
      "Model: Temp_0.5\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 49s 5s/step - loss: 1.7915 - val_loss: 1.7919\n",
      "Model: Temp_1.5\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 49s 5s/step - loss: 1.7917 - val_loss: 1.7918\n",
      "Model: Temp_1\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 52s 5s/step - loss: 1.7917 - val_loss: 1.7918\n",
      "Model: Temp_sum_normal\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 49s 5s/step - loss: 1.7911 - val_loss: 1.7913\n"
     ]
    }
   ],
   "source": [
    "all_history = None\n",
    "for epoch in range(10):\n",
    "    for k in train_seq.keys():\n",
    "        name = f'Temp_{k}'\n",
    "        print(f'Model: {name}')\n",
    "        load_file = 'blank.keras' if epoch==0 else f'{k}_e{epoch-1:0=2}.keras'\n",
    "        student.model.load_weights(os.path.join(student_par, load_file))\n",
    "        student.model.compile(\"adam\",\n",
    "                    tf.keras.losses.CategoricalCrossentropy(),\n",
    "                    jit_compile=True)\n",
    "        hist = student.model.fit(\n",
    "            train_seq[k],\n",
    "            validation_data=val_seq[k],\n",
    "            epochs=epoch+1,\n",
    "            initial_epoch=epoch\n",
    "        )\n",
    "        student.model.save_weights(os.path.join(student_par, f'{k}_e{epoch:0=2}.keras'))\n",
    "        hist.history['model'] = [name]\n",
    "        hist.history['epoch'] = [epoch+1]\n",
    "        history = pd.DataFrame(hist.history)\n",
    "        if all_history is None:\n",
    "            all_history = history\n",
    "        else:\n",
    "            all_history = pd.concat([all_history, history])\n",
    "        all_history.to_csv('student_history.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'student_models\\\\1_e09.keras',\n",
       " b'student_models\\\\sum_normal_e09.keras',\n",
       " b'student_models\\\\0.05_e09.keras',\n",
       " b'student_models\\\\0.1_e09.keras',\n",
       " b'student_models\\\\1.5_e09.keras',\n",
       " b'student_models\\\\0.5_e09.keras']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tf.data.Dataset.list_files(\"student_models\\\\*_e09.keras\").as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "res = student.model(np.random.random((1,200,320,3)))\n",
    "tf.argmax(res[0]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "student.model.load_weights(\"student_models\\\\blank.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6), dtype=float32, numpy=array([[0., 1., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student.model(np.random.random((1,200,320,3))*10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(layers=[\n",
    "    tf.keras.layers.Conv2D(32, (5,5), input_shape=(200,320,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D((5,5)),\n",
    "    tf.keras.layers.Conv2D(32, (5,5), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D((5,5)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1000, 'relu'),\n",
    "    tf.keras.layers.Dense(1000, 'relu'),\n",
    "    tf.keras.layers.Dense(100, 'relu'),\n",
    "    tf.keras.layers.Dense(6, 'softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"student_models\\\\blank.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6), dtype=float32, numpy=\n",
       "array([[0.15038343, 0.20452508, 0.15909198, 0.14421031, 0.17543429,\n",
       "        0.16635491]], dtype=float32)>"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(np.random.random((1,200,320,3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
